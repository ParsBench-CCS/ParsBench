{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e80e37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAG=MISTRAL_7B_V03\n",
      "endpoint=http://192.168.0.222:80/v1/chat/completions\n",
      "model=mistralai/Mistral-7B-Instruct-v0.3\n",
      "Found 1 category files.\n",
      "\n",
      "=== Running: banking_1_with_mcq_fa_T_evol_GN_RD_GNge4_RDge4_BALANCED.json ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MISTRAL_7B_V03 | banking_1_with_mcq_fa_T_evol_GN_RD_GNge4_RDge4_BALANCED: 100%|██████████| 643/643 [12:39<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[banking_1_with_mcq_fa_T_evol_GN_RD_GNge4_RDge4_BALANCED] total=643 called=643 saved_rows=643 skip_no_evol=0 skip_no_q=0 skip_bad_opt=0 valid=643 acc=0.4510\n",
      "\n",
      "=========================\n",
      "[saved] ALL categories summary: ./mistral_7B_eval_outputs/MISTRAL_7B_V03_metrics_summary_ALL_categories.csv\n",
      "Per-category outputs saved under: ./mistral_7B_eval_outputs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Any, List, Optional, Tuple\n",
    "\n",
    "\n",
    "ENDPOINT = \"..\"\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "TAG = \"MISTRAL_7B_V03\"\n",
    "\n",
    "\n",
    "IN_DIR = \"../Dataset-commonSence/GN_RD_ge4_only_json_balanced\"\n",
    "IN_PATTERN = \"b*_BALANCED.json\"\n",
    "\n",
    "OUT_DIR = \"./mistral_7B_eval_outputs\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "OUT_SUMMARY_ALL = os.path.join(OUT_DIR, f\"{TAG}_metrics_summary_ALL_categories.csv\")\n",
    "\n",
    "# =========================\n",
    "# DATA KEYS\n",
    "# =========================\n",
    "QA_KEY = \"qa_fa\"\n",
    "MCQ_KEY = \"mcq\"\n",
    "EVOL_KEY = \"mcq_evol\"\n",
    "\n",
    "GOLD_RATIONALE_KEY = \"rationale\"\n",
    "GOLD_ANSWER_KEY    = \"answer\"\n",
    "EVOL_CORRECT_KEY   = \"correct_answer\"\n",
    "\n",
    "RQ_KEY = \"rewritten_question\"\n",
    "RO_KEY = \"rewritten_options\"\n",
    "\n",
    "CHOICES = [\"A\", \"B\", \"C\", \"D\"]\n",
    "\n",
    "# =========================\n",
    "# PROMPTING\n",
    "# =========================\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a careful multiple-choice question solver.\\n\"\n",
    "    \"Return ONLY a valid JSON object with keys: answer, rationale.\\n\"\n",
    "    \"answer must be one of: A, B, C, D.\\n\"\n",
    "    \"rationale must be concise (2-5 sentences), logical, and based only on the question/options.\\n\"\n",
    "    \"Do not include any extra keys or text outside JSON.\"\n",
    ")\n",
    "\n",
    "def build_user_prompt(question: str, options: Dict[str, str]) -> str:\n",
    "    opts = \"\\n\".join([f\"{k}) {options.get(k,'')}\" for k in CHOICES])\n",
    "    return (\n",
    "        f\"Question (Persian):\\n{question}\\n\\n\"\n",
    "        f\"Options:\\n{opts}\\n\\n\"\n",
    "        f'Return JSON like:\\n{{\"answer\":\"A\",\"rationale\":\"...\"}}'\n",
    "    )\n",
    "\n",
    "# =========================\n",
    "# API CALL\n",
    "# =========================\n",
    "def call_chat_completions(\n",
    "    endpoint: str,\n",
    "    model: str,\n",
    "    system_prompt: str,\n",
    "    user_prompt: str,\n",
    "    timeout: int = 180,\n",
    "    max_retries: int = 6,\n",
    "    backoff_base: float = 1.8,\n",
    ") -> Dict[str, Any]:\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        \"temperature\": 0.0,\n",
    "        \"max_tokens\": 200,\n",
    "        \"max_new_tokens\": 200,\n",
    "    }\n",
    "\n",
    "    last_err: Optional[Exception] = None\n",
    "    last_status: Optional[int] = None\n",
    "    last_body: str = \"\"\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            r = requests.post(endpoint, json=payload, timeout=timeout)\n",
    "            last_status = r.status_code\n",
    "            last_body = (r.text or \"\")[:800]\n",
    "\n",
    "            if r.status_code in (408, 425, 429) or r.status_code >= 500:\n",
    "                time.sleep((backoff_base ** attempt) + 0.1)\n",
    "                continue\n",
    "\n",
    "            r.raise_for_status()\n",
    "            return r.json()\n",
    "\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            time.sleep((backoff_base ** attempt) + 0.1)\n",
    "\n",
    "    raise RuntimeError(\n",
    "        f\"Failed after retries.\\n\"\n",
    "        f\"endpoint={endpoint}\\nmodel={model}\\n\"\n",
    "        f\"last_status={last_status}\\nlast_body={last_body}\\nlast_error={repr(last_err)}\"\n",
    "    )\n",
    "\n",
    "def extract_text(resp_json: Dict[str, Any]) -> str:\n",
    "    try:\n",
    "        return resp_json[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def safe_parse_json_object(text: str) -> Optional[Dict[str, Any]]:\n",
    "   \n",
    "    if not text:\n",
    "        return None\n",
    "    s = text.strip()\n",
    "\n",
    "    if s.startswith(\"```\"):\n",
    "        s = s.strip(\"`\").strip()\n",
    "        if s.startswith(\"json\"):\n",
    "            s = s[4:].strip()\n",
    "\n",
    "    l = s.find(\"{\")\n",
    "    r = s.rfind(\"}\")\n",
    "    if l == -1 or r == -1 or r <= l:\n",
    "        return None\n",
    "\n",
    "    candidate = s[l:r+1]\n",
    "    try:\n",
    "        obj = json.loads(candidate)\n",
    "        return obj if isinstance(obj, dict) else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# =========================\n",
    "# I/O HELPERS\n",
    "# =========================\n",
    "def load_json_array(path: str) -> List[Dict[str, Any]]:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    if not isinstance(data, list):\n",
    "        raise ValueError(f\"Input must be a JSON array (list). Bad file: {path}\")\n",
    "    return data\n",
    "\n",
    "def get_question_and_options(item: Dict[str, Any]) -> Tuple[str, Dict[str, str], Dict[str, Any]]:\n",
    "    \"\"\"Returns (question, options_dict, evol_dict_for_debug).\"\"\"\n",
    "    evol = (((item.get(QA_KEY) or {}).get(EVOL_KEY)) or {})\n",
    "    rq = (evol.get(RQ_KEY) or \"\").strip()\n",
    "    ro = evol.get(RO_KEY) or {}\n",
    "    if not isinstance(ro, dict):\n",
    "        ro = {}\n",
    "    options = {k: (ro.get(k) or \"\").strip() for k in CHOICES}\n",
    "    return rq, options, evol\n",
    "\n",
    "def get_gold(item: Dict[str, Any]) -> Tuple[str, str]:\n",
    "    qa = item.get(QA_KEY) or {}\n",
    "    mcq = qa.get(MCQ_KEY) or {}\n",
    "    evol = qa.get(EVOL_KEY) or {}\n",
    "    gold_rationale = (mcq.get(GOLD_RATIONALE_KEY) or \"\").strip()\n",
    "    gold_answer = (evol.get(EVOL_CORRECT_KEY) or mcq.get(GOLD_ANSWER_KEY) or \"\").strip().upper()\n",
    "    return gold_rationale, gold_answer\n",
    "\n",
    "def compute_sbert_similarities(pairs: List[Tuple[str, str]]) -> List[float]:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\")\n",
    "\n",
    "    pred_texts = [p for p, _ in pairs]\n",
    "    gold_texts = [g for _, g in pairs]\n",
    "\n",
    "    emb_pred = model.encode(pred_texts, convert_to_numpy=True, normalize_embeddings=True, batch_size=32)\n",
    "    emb_gold = model.encode(gold_texts, convert_to_numpy=True, normalize_embeddings=True, batch_size=32)\n",
    "    sims = (emb_pred * emb_gold).sum(axis=1)\n",
    "    return sims.tolist()\n",
    "\n",
    "def mean(xs: List[float]) -> float:\n",
    "    return sum(xs) / len(xs) if xs else 0.0\n",
    "\n",
    "# =========================\n",
    "# CORE RUN\n",
    "# =========================\n",
    "def run_one_file(in_path: str, limit: Optional[int]) -> Dict[str, Any]:\n",
    "    base = os.path.basename(in_path).replace(\".json\", \"\")\n",
    "\n",
    "    out_pred_jsonl  = os.path.join(OUT_DIR, f\"{base}__{TAG}__predictions.jsonl\")\n",
    "    out_peritem_csv = os.path.join(OUT_DIR, f\"{base}__{TAG}__per_item.csv\")\n",
    "    out_metrics_csv = os.path.join(OUT_DIR, f\"{base}__{TAG}__metrics.csv\")\n",
    "\n",
    "    data = load_json_array(in_path)\n",
    "    if limit is not None:\n",
    "        data = data[:limit]\n",
    "\n",
    "    open(out_pred_jsonl, \"w\", encoding=\"utf-8\").close()\n",
    "\n",
    "    per_item_rows = []\n",
    "    sim_pairs = []\n",
    "    sim_pair_indices = []\n",
    "\n",
    "    skipped_no_question = 0\n",
    "    skipped_bad_options = 0\n",
    "    skipped_no_evol = 0\n",
    "    called = 0\n",
    "\n",
    "    for idx, item in enumerate(tqdm(data, desc=f\"{TAG} | {base}\")):\n",
    "        question, options, evol_dbg = get_question_and_options(item)\n",
    "        gold_rationale, gold_answer = get_gold(item)\n",
    "\n",
    "     \n",
    "        if not isinstance(evol_dbg, dict) or not evol_dbg:\n",
    "            skipped_no_evol += 1\n",
    "            continue\n",
    "\n",
    "        if not question:\n",
    "            skipped_no_question += 1\n",
    "            continue\n",
    "\n",
    "        nonempty = sum(1 for k in CHOICES if options.get(k, \"\").strip())\n",
    "        if nonempty < 2:\n",
    "            skipped_bad_options += 1\n",
    "            continue\n",
    "\n",
    "        called += 1\n",
    "        user_prompt = build_user_prompt(question, options)\n",
    "        resp = call_chat_completions(ENDPOINT, MODEL_NAME, SYSTEM_PROMPT, user_prompt)\n",
    "\n",
    "        raw_text = extract_text(resp)\n",
    "        parsed = safe_parse_json_object(raw_text) or {}\n",
    "\n",
    "        pred_answer = (parsed.get(\"answer\") or \"\").strip().upper()\n",
    "        pred_rationale = (parsed.get(\"rationale\") or \"\").strip()\n",
    "\n",
    "        if pred_answer not in CHOICES:\n",
    "            pred_answer = \"\"\n",
    "\n",
    "        is_correct = int(bool(gold_answer) and pred_answer == gold_answer)\n",
    "\n",
    "        row = {\n",
    "            \"idx\": idx,\n",
    "            \"gold_answer\": gold_answer,\n",
    "            \"pred_answer\": pred_answer,\n",
    "            \"is_correct\": is_correct,\n",
    "            \"question\": question,\n",
    "            \"gold_rationale\": gold_rationale,\n",
    "            \"pred_rationale\": pred_rationale,\n",
    "            \"sbert_sim\": \"\",\n",
    "        }\n",
    "        per_item_rows.append(row)\n",
    "\n",
    "        with open(out_pred_jsonl, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(json.dumps({\n",
    "                \"idx\": idx,\n",
    "                \"gold_answer\": gold_answer,\n",
    "                \"pred_answer\": pred_answer,\n",
    "                \"pred_rationale\": pred_rationale,\n",
    "                \"raw_model_text\": raw_text,\n",
    "            }, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "        if gold_rationale and pred_rationale:\n",
    "            sim_pairs.append((pred_rationale, gold_rationale))\n",
    "            sim_pair_indices.append(idx)\n",
    "\n",
    "    # --- fill SBERT sims ---\n",
    "    if sim_pairs:\n",
    "        sims = compute_sbert_similarities(sim_pairs)\n",
    "        idx_to_sim = {i: s for i, s in zip(sim_pair_indices, sims)}\n",
    "        for row in per_item_rows:\n",
    "            i = row[\"idx\"]\n",
    "            if i in idx_to_sim:\n",
    "                row[\"sbert_sim\"] = float(round(idx_to_sim[i], 6))\n",
    "\n",
    "    n_total = len(data)\n",
    "    n_used = len(per_item_rows)\n",
    "    n_valid = sum(1 for r in per_item_rows if r[\"gold_answer\"] and r[\"pred_answer\"])\n",
    "    n_correct = sum(r[\"is_correct\"] for r in per_item_rows)\n",
    "    acc = (n_correct / n_valid) if n_valid else 0.0\n",
    "\n",
    "    sims_all = [r[\"sbert_sim\"] for r in per_item_rows if isinstance(r[\"sbert_sim\"], float)]\n",
    "    sims_correct = [r[\"sbert_sim\"] for r in per_item_rows if isinstance(r[\"sbert_sim\"], float) and r[\"is_correct\"] == 1]\n",
    "    sims_wrong = [r[\"sbert_sim\"] for r in per_item_rows if isinstance(r[\"sbert_sim\"], float) and r[\"is_correct\"] == 0]\n",
    "\n",
    "    summary = {\n",
    "        \"category_file\": os.path.basename(in_path),\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"endpoint\": ENDPOINT,\n",
    "        \"N_items_total\": n_total,\n",
    "        \"N_items_called\": called,\n",
    "        \"N_rows_saved\": n_used,\n",
    "        \"skipped_no_evol\": skipped_no_evol,\n",
    "        \"skipped_no_question\": skipped_no_question,\n",
    "        \"skipped_bad_options\": skipped_bad_options,\n",
    "        \"N_valid_for_accuracy\": n_valid,\n",
    "        \"N_correct\": n_correct,\n",
    "        \"accuracy\": round(acc, 6),\n",
    "        \"N_sbert_pairs\": len(sims_all),\n",
    "        \"sbert_mean_all\": round(mean(sims_all), 6),\n",
    "        \"sbert_mean_correct\": round(mean(sims_correct), 6),\n",
    "        \"sbert_mean_wrong\": round(mean(sims_wrong), 6),\n",
    "        \"pred_jsonl\": out_pred_jsonl,\n",
    "        \"per_item_csv\": out_peritem_csv,\n",
    "        \"metrics_csv\": out_metrics_csv,\n",
    "    }\n",
    "\n",
    "    if per_item_rows:\n",
    "        with open(out_peritem_csv, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "            cols = list(per_item_rows[0].keys())\n",
    "            w = csv.DictWriter(f, fieldnames=cols)\n",
    "            w.writeheader()\n",
    "            w.writerows(per_item_rows)\n",
    "\n",
    "    with open(out_metrics_csv, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        cols = list(summary.keys())\n",
    "        w = csv.DictWriter(f, fieldnames=cols)\n",
    "        w.writeheader()\n",
    "        w.writerow(summary)\n",
    "\n",
    "    print(\n",
    "        f\"[{base}] total={n_total} called={called} saved_rows={n_used} \"\n",
    "        f\"skip_no_evol={skipped_no_evol} skip_no_q={skipped_no_question} skip_bad_opt={skipped_bad_options} \"\n",
    "        f\"valid={n_valid} acc={acc:.4f}\"\n",
    "    )\n",
    "\n",
    "    return summary\n",
    "\n",
    "def main(limit_per_category: Optional[int] = None):\n",
    "    in_files = sorted(glob.glob(os.path.join(IN_DIR, IN_PATTERN)))\n",
    "    if not in_files:\n",
    "        raise SystemExit(f\"No files matched: {os.path.join(IN_DIR, IN_PATTERN)}\")\n",
    "\n",
    "    all_summaries = []\n",
    "    print(f\"TAG={TAG}\")\n",
    "    print(f\"endpoint={ENDPOINT}\")\n",
    "    print(f\"model={MODEL_NAME}\")\n",
    "    print(f\"Found {len(in_files)} category files.\")\n",
    "\n",
    "    for in_path in in_files:\n",
    "        print(f\"\\n=== Running: {os.path.basename(in_path)} ===\")\n",
    "        s = run_one_file(in_path, limit=limit_per_category)\n",
    "        all_summaries.append(s)\n",
    "\n",
    "    with open(OUT_SUMMARY_ALL, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        cols = list(all_summaries[0].keys())\n",
    "        w = csv.DictWriter(f, fieldnames=cols)\n",
    "        w.writeheader()\n",
    "        w.writerows(all_summaries)\n",
    "\n",
    "    print(\"\\n=========================\")\n",
    "    print(f\"[saved] ALL categories summary: {OUT_SUMMARY_ALL}\")\n",
    "    print(f\"Per-category outputs saved under: {OUT_DIR}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(limit_per_category=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
