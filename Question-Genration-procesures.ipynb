{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bdd043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Processed: 1000/1000 | failed: 89 | total time: 5h 28m 31s\n",
      "Saved to: /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "INPUT_PATH = \"../Dataset-commonSence/traditions_and_customs_1.json\"\n",
    "OUTPUT_PATH = \"../Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T.json\"\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "ENDPOINT = \"...\"\n",
    "\n",
    "SAVE_EVERY = 10\n",
    "SLEEP_BETWEEN_CALLS = 0.10\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "MAX_TOKENS = 320\n",
    "TEMPERATURE = 0.2\n",
    "TOP_P = 0.95\n",
    "\n",
    "MIN_WORDS_PER_TEXT = 40\n",
    "MIN_WORDS_PER_DESC = 8\n",
    "MIN_ASSUMPTIONS = 2\n",
    "\n",
    "PRINT_EVERY = 10\n",
    "\n",
    "TEXT_KEY = \"text\"\n",
    "\n",
    "SYSTEM_MCQ = (\n",
    "    \"You generate exactly ONE multiple-choice challenging and reasoning question (MCQ) in Persian. \"\n",
    "    \"Use strictly the provided Text. \"\n",
    "    \"Do NOT add new facts, names, places, foods, crafts, or claims. \"\n",
    "    \"Do NOT use external knowledge. \"\n",
    "    \"strictly Do NOT use phrases such as according to the text, or based on the information provided, or the text states,  or based on the text, or any form of direct quotation.\"\n",
    "    \"Return VALID JSON ONLY with the exact schema; no markdown, no code fences.\"\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# PROMPT\n",
    "# =========================\n",
    "def build_user_prompt_mcq(text_fa: str) -> str:\n",
    "   \n",
    "\n",
    "    return f\"\"\"\n",
    "Using the “text,” generate exactly one multiple-choice question (MCQ) in Persian.\n",
    "Text:\n",
    "{text_fa}\n",
    "\n",
    "Strict rules:\n",
    "\n",
    "- The question must be written entirely in Persian.\n",
    "- strictly Do NOT use phrases such as “according to the text,” or \"based on the information provided\" or “the text states,”  or “based on the text,” or any form of direct quotation.\n",
    "\n",
    "- The question must require reasoning (at least two steps of reasoning).\n",
    "\n",
    "- The question must be text-grounded: within the question itself, refer to at least two specific clues/details from the text (without direct quotation).\n",
    "\n",
    "- The correct answer must be inferable solely based on the text.\n",
    "\n",
    "- Do not add any new names, places, entities, or claims.\n",
    "\n",
    "-The output must be valid JSON only (no Markdown, no code blocks, no extra text).\n",
    "\n",
    "-The \"rationale\" field is mandatory and must be one short paragraph, written in Persian, that:\n",
    "\n",
    "refers indirectly (without quotation) to relevant points from the text, and\n",
    "\n",
    "concisely explains the two reasoning steps.\n",
    "\n",
    "-There must be only one correct answer.\n",
    "\n",
    "Exact output format:\n",
    "\n",
    "{{\n",
    "  \"mcq\": {{\n",
    "    \"question\": \"\",\n",
    "    \"choices\": {{\n",
    "      \"A\": \"\",\n",
    "      \"B\": \"\",\n",
    "      \"C\": \"\",\n",
    "      \"D\": \"\"\n",
    "    }},\n",
    "    \"answer\": \"A\",\n",
    "    \"rationale\": \"\"\n",
    "  }}\n",
    "}}\n",
    "\n",
    "\"\"\".strip()\n",
    "# =========================\n",
    "# IO\n",
    "# =========================\n",
    "def load_json(path: str):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(path: str, data):\n",
    "    tmp_path = path + \".tmp\"\n",
    "    with open(tmp_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    os.replace(tmp_path, path)\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def word_count(s: str) -> int:\n",
    "    s = (s or \"\").strip()\n",
    "    if not s:\n",
    "        return 0\n",
    "\n",
    "    return len([w for w in s.split() if w])\n",
    "\n",
    "def format_hms(seconds: float) -> str:\n",
    "    seconds = max(0.0, float(seconds))\n",
    "    h = int(seconds // 3600)\n",
    "    m = int((seconds % 3600) // 60)\n",
    "    s = int(seconds % 60)\n",
    "    return f\"{h:d}h {m:02d}m {s:02d}s\" if h > 0 else f\"{m:d}m {s:02d}s\"\n",
    "\n",
    "def strip_code_fences(text: str) -> str:\n",
    "    text = (text or \"\").strip()\n",
    "\n",
    "    if text.startswith(\"```\"):\n",
    "        text = text.split(\"```\", 1)[-1].strip()\n",
    "        if \"\\n\" in text:\n",
    "            first = text.split(\"\\n\", 1)[0].strip().lower()\n",
    "            if first in (\"json\", \"javascript\"):\n",
    "                text = text.split(\"\\n\", 1)[-1].strip()\n",
    "\n",
    "    if text.endswith(\"```\"):\n",
    "        text = text.rsplit(\"```\", 1)[0].strip()\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "def safe_parse_json_obj(text: str):\n",
    "    try:\n",
    "        cleaned = strip_code_fences(text)\n",
    "        obj = json.loads(cleaned)\n",
    "        return obj if isinstance(obj, dict) else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def valid_mcq_schema(obj) -> bool:\n",
    "    try:\n",
    "        if \"mcq\" not in obj:\n",
    "            return False\n",
    "        mcq = obj[\"mcq\"]\n",
    "        for k in [\"question\", \"choices\", \"answer\", \"rationale\"]:\n",
    "            if k not in mcq:\n",
    "                return False\n",
    "        if not isinstance(mcq[\"choices\"], dict):\n",
    "            return False\n",
    "        for ch in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "            if ch not in mcq[\"choices\"]:\n",
    "                return False\n",
    "            if not isinstance(mcq[\"choices\"][ch], str) or not mcq[\"choices\"][ch].strip():\n",
    "                return False\n",
    "        if mcq[\"answer\"] not in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "            return False\n",
    "        if not isinstance(mcq[\"question\"], str) or len(mcq[\"question\"].strip()) < 10:\n",
    "            return False\n",
    "        if not isinstance(mcq[\"rationale\"], str) or len(mcq[\"rationale\"].strip()) < 10:\n",
    "            return False\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def should_process(rec) -> bool:\n",
    "    if not isinstance(rec, dict):\n",
    "        return False\n",
    "\n",
    "    text = rec.get(TEXT_KEY)\n",
    "   \n",
    "\n",
    "\n",
    "    if word_count(text) < MIN_WORDS_PER_TEXT:\n",
    "        return False\n",
    "  \n",
    "\n",
    "    qa = rec.get(\"qa_fa\")\n",
    "    if isinstance(qa, dict) and isinstance(qa.get(\"mcq\"), dict):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "# =========================\n",
    "# LLAMA CALL (OpenAI-compatible chat/completions)\n",
    "# =========================\n",
    "session = requests.Session()\n",
    "\n",
    "def call_llama(system_prompt: str, user_prompt: str) -> str:\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        \"max_tokens\": MAX_TOKENS,\n",
    "        \"temperature\": TEMPERATURE,\n",
    "        \"top_p\": TOP_P,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    resp = session.post(ENDPOINT, json=payload, timeout=(10, 120))\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    try:\n",
    "        return (data[\"choices\"][0][\"message\"][\"content\"] or \"\").strip()\n",
    "    except Exception:\n",
    "        raise RuntimeError(f\"Unexpected response format: {data}\")\n",
    "\n",
    "def with_retries(fn, *args):\n",
    "    last_err = None\n",
    "    for attempt in range(1, MAX_RETRIES + 1):\n",
    "        try:\n",
    "            return fn(*args), None\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            time.sleep(1.5 * attempt)\n",
    "    return None, str(last_err)\n",
    "\n",
    "# =========================\n",
    "# MAIN\n",
    "# =========================\n",
    "t0 = time.time()\n",
    "print(\"Loading INPUT json...\", flush=True)\n",
    "data = load_json(INPUT_PATH)\n",
    "print(f\"Loaded INPUT in {time.time()-t0:.1f}s | records={len(data)}\", flush=True)\n",
    "\n",
    "if os.path.exists(OUTPUT_PATH):\n",
    "    t1 = time.time()\n",
    "    print(\"Loading OUTPUT json...\", flush=True)\n",
    "    existing = load_json(OUTPUT_PATH)\n",
    "    print(f\"Loaded OUTPUT in {time.time()-t1:.1f}s | records={len(existing)}\", flush=True)\n",
    "else:\n",
    "    existing = data\n",
    "    print(\"No OUTPUT file; using INPUT as base.\", flush=True)\n",
    "\n",
    "print(\"Pre-scan counting eligible records...\", flush=True)\n",
    "t2 = time.time()\n",
    "total_to_process = 0\n",
    "seen = 0\n",
    "for rec in existing:\n",
    "    seen += 1\n",
    "    if seen % 10000 == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Pre-scan: seen={seen} | eligible_so_far={total_to_process} | elapsed={format_hms(time.time()-t2)}\")\n",
    "    if should_process(rec):\n",
    "        total_to_process += 1\n",
    "\n",
    "clear_output(wait=True)\n",
    "print(f\"Pre-scan done: total_to_process={total_to_process} in {format_hms(time.time()-t2)}\", flush=True)\n",
    "\n",
    "processed = 0\n",
    "failed = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for rec in existing:\n",
    "    if not should_process(rec):\n",
    "        continue\n",
    "\n",
    "    text_fa = rec[TEXT_KEY].strip()\n",
    "   \n",
    "\n",
    "    call_t0 = time.time()\n",
    "    raw, err = with_retries(\n",
    "        call_llama,\n",
    "        SYSTEM_MCQ,\n",
    "        build_user_prompt_mcq(text_fa),\n",
    "    )\n",
    "    call_dt = time.time() - call_t0\n",
    "\n",
    "    if raw is None:\n",
    "        rec[\"qa_fa\"] = {}\n",
    "        rec[\"qa_error\"] = err\n",
    "        failed += 1\n",
    "    else:\n",
    "        obj = safe_parse_json_obj(raw)\n",
    "        if obj is None or not valid_mcq_schema(obj):\n",
    "            rec[\"qa_fa\"] = {}\n",
    "            rec[\"qa_error\"] = f\"Invalid JSON/schema. Raw: {raw[:450]}\"\n",
    "            failed += 1\n",
    "        else:\n",
    "            rec[\"qa_fa\"] = obj\n",
    "            rec.pop(\"qa_error\", None)\n",
    "\n",
    "    processed += 1\n",
    "\n",
    "    if processed % PRINT_EVERY == 0 or processed == total_to_process:\n",
    "        elapsed = time.time() - start_time\n",
    "        rate = processed / elapsed if elapsed > 0 else 0.0\n",
    "        remaining = total_to_process - processed\n",
    "        eta = remaining / rate if rate > 0 else float(\"inf\")\n",
    "        pct = (processed / total_to_process * 100) if total_to_process > 0 else 100.0\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(\n",
    "            f\"[{processed}/{total_to_process}] {pct:6.2f}% | \"\n",
    "            f\"last_call={call_dt:.1f}s | \"\n",
    "            f\"elapsed {format_hms(elapsed)} | \"\n",
    "            f\"rate {rate:.3f} rec/s | \"\n",
    "            f\"ETA {format_hms(eta)} | failed {failed}\"\n",
    "        )\n",
    "\n",
    "    if processed % SAVE_EVERY == 0:\n",
    "        save_json(OUTPUT_PATH, existing)\n",
    "\n",
    "    time.sleep(SLEEP_BETWEEN_CALLS)\n",
    "\n",
    "save_json(OUTPUT_PATH, existing)\n",
    "\n",
    "elapsed_total = time.time() - start_time\n",
    "clear_output(wait=True)\n",
    "print(f\"Done. Processed: {processed}/{total_to_process} | failed: {failed} | total time: {format_hms(elapsed_total)}\")\n",
    "print(f\"Saved to: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae935e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-scan done: total_to_process=911 in 0m 00s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 249\u001b[39m\n\u001b[32m    246\u001b[39m answer = mcq.get(\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    248\u001b[39m call_t0 = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m raw, err = \u001b[43mwith_retries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcall_llama\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m    \u001b[49m\u001b[43mSYSTEM_EVOL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbuild_user_prompt_evol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchoices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m call_dt = time.time() - call_t0\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m raw \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 204\u001b[39m, in \u001b[36mwith_retries\u001b[39m\u001b[34m(fn, *args)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, MAX_RETRIES + \u001b[32m1\u001b[39m):\n\u001b[32m    203\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    206\u001b[39m         last_err = e\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 192\u001b[39m, in \u001b[36mcall_llama\u001b[39m\u001b[34m(system_prompt, user_prompt)\u001b[39m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_llama\u001b[39m(system_prompt: \u001b[38;5;28mstr\u001b[39m, user_prompt: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    181\u001b[39m     payload = {\n\u001b[32m    182\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: MODEL_NAME,\n\u001b[32m    183\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m   (...)\u001b[39m\u001b[32m    190\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    191\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     resp = \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mENDPOINT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m120\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m     resp.raise_for_status()\n\u001b[32m    194\u001b[39m     data = resp.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.12/site-packages/requests/sessions.py:637\u001b[39m, in \u001b[36mSession.post\u001b[39m\u001b[34m(self, url, data, json, **kwargs)\u001b[39m\n\u001b[32m    626\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    627\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[32m    628\u001b[39m \n\u001b[32m    629\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    634\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    635\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m637\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.12/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.12/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.12/site-packages/requests/adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.12/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venv/lib/python3.12/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    568\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:1428\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1426\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1427\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1428\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1430\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/socket.py:707\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    709\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "INPUT_PATH = \"../Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T.json\"\n",
    "OUTPUT_PATH = \"../Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol.json\"\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "ENDPOINT   = \"...\"\n",
    "\n",
    "SAVE_EVERY = 10\n",
    "SLEEP_BETWEEN_CALLS = 0.10\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "MAX_TOKENS = 420\n",
    "TEMPERATURE = 0.2\n",
    "TOP_P = 0.95\n",
    "\n",
    "PRINT_EVERY = 10\n",
    "\n",
    "\n",
    "QA_KEY = \"qa_fa\"\n",
    "MCQ_KEY = \"mcq\"\n",
    "\n",
    "\n",
    "EVOL_KEY = \"mcq_evol\"\n",
    "\n",
    "# =========================\n",
    "# SYSTEM PROMPT \n",
    "# =========================\n",
    "SYSTEM_EVOL = (\n",
    "     \"You are a Question Rewriter. Your objective is to rewrite the given question into a more complex version \"\n",
    "    \"to make those famous AI systems (e.g., ChatGPT, Gemini etc.) a bit harder to handle. But the rewritten \"\n",
    "    \"question must be reasonable and must be understood and responded by humans. You may also modify the answer \"\n",
    "    \"options to increase difficulty and reduce genericness.\\n\\n\"\n",
    "    \"Constraints:\\n\"\n",
    "    \"• Do not change the core meaning of the original question.\\n\"\n",
    "    \"• Do not make the rewritten question overly verbose.\"\n",
    ")\n",
    "\n",
    "\n",
    "def build_user_prompt_evol(question: str, choices: dict, answer: str) -> str:\n",
    "    \n",
    "    A = choices.get(\"A\", \"\")\n",
    "    B = choices.get(\"B\", \"\")\n",
    "    C = choices.get(\"C\", \"\")\n",
    "    D = choices.get(\"D\", \"\")\n",
    "\n",
    "    return f\"\"\"\n",
    "Original Question:\n",
    "{question}\n",
    "\n",
    "Answer Options:\n",
    "A) {A}\n",
    "B) {B}\n",
    "C) {C}\n",
    "D) {D}\n",
    "\n",
    "Correct Answer:\n",
    "{answer}\n",
    "\n",
    "Output format (JSON only):\n",
    "{{\n",
    "  \"rewritten_question\": \"\",\n",
    "  \"rewritten_options\": {{\n",
    "    \"A\": \"\",\n",
    "    \"B\": \"\",\n",
    "    \"C\": \"\",\n",
    "    \"D\": \"\"\n",
    "  }},\n",
    "  \"correct_answer\": \"\"\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n",
    "# =========================\n",
    "# IO\n",
    "# =========================\n",
    "def load_json(path: str):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(path: str, data):\n",
    "    tmp_path = path + \".tmp\"\n",
    "    with open(tmp_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    os.replace(tmp_path, path)\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def format_hms(seconds: float) -> str:\n",
    "    seconds = max(0.0, float(seconds))\n",
    "    h = int(seconds // 3600)\n",
    "    m = int((seconds % 3600) // 60)\n",
    "    s = int(seconds % 60)\n",
    "    return f\"{h:d}h {m:02d}m {s:02d}s\" if h > 0 else f\"{m:d}m {s:02d}s\"\n",
    "\n",
    "def strip_code_fences(text: str) -> str:\n",
    "    text = (text or \"\").strip()\n",
    "    if text.startswith(\"```\"):\n",
    "        text = text.split(\"```\", 1)[-1].strip()\n",
    "        if \"\\n\" in text:\n",
    "            first = text.split(\"\\n\", 1)[0].strip().lower()\n",
    "            if first in (\"json\", \"javascript\"):\n",
    "                text = text.split(\"\\n\", 1)[-1].strip()\n",
    "    if text.endswith(\"```\"):\n",
    "        text = text.rsplit(\"```\", 1)[0].strip()\n",
    "    return text.strip()\n",
    "\n",
    "def safe_parse_json_obj(text: str):\n",
    "    try:\n",
    "        cleaned = strip_code_fences(text)\n",
    "        \n",
    "        i = cleaned.find(\"{\")\n",
    "        j = cleaned.rfind(\"}\")\n",
    "        if i == -1 or j == -1 or j <= i:\n",
    "            return None\n",
    "        cleaned = cleaned[i:j+1]\n",
    "        obj = json.loads(cleaned)\n",
    "        return obj if isinstance(obj, dict) else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def valid_evol_schema(obj) -> bool:\n",
    "    try:\n",
    "        for k in [\"rewritten_question\", \"rewritten_options\", \"correct_answer\"]:\n",
    "            if k not in obj:\n",
    "                return False\n",
    "        if not isinstance(obj[\"rewritten_question\"], str) or len(obj[\"rewritten_question\"].strip()) < 5:\n",
    "            return False\n",
    "        if not isinstance(obj[\"rewritten_options\"], dict):\n",
    "            return False\n",
    "        for ch in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "            if ch not in obj[\"rewritten_options\"]:\n",
    "                return False\n",
    "            if not isinstance(obj[\"rewritten_options\"][ch], str) or not obj[\"rewritten_options\"][ch].strip():\n",
    "                return False\n",
    "        if obj[\"correct_answer\"] not in [\"A\", \"B\", \"C\", \"D\"]:\n",
    "            return False\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def has_mcq(rec) -> bool:\n",
    "    qa = rec.get(QA_KEY)\n",
    "    if not isinstance(qa, dict):\n",
    "        return False\n",
    "    mcq = qa.get(MCQ_KEY)\n",
    "    return isinstance(mcq, dict)\n",
    "\n",
    "def should_process(rec) -> bool:\n",
    "    \n",
    "    if not isinstance(rec, dict):\n",
    "        return False\n",
    "    qa = rec.get(QA_KEY)\n",
    "    if not isinstance(qa, dict):\n",
    "        return False\n",
    "    mcq = qa.get(MCQ_KEY)\n",
    "    if not isinstance(mcq, dict):\n",
    "        return False\n",
    "    if isinstance(qa.get(EVOL_KEY), dict):\n",
    "        return False\n",
    "    \n",
    "    if not mcq.get(\"question\") or not isinstance(mcq.get(\"choices\"), dict) or mcq.get(\"answer\") not in [\"A\",\"B\",\"C\",\"D\"]:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "session = requests.Session()\n",
    "\n",
    "def call_llama(system_prompt: str, user_prompt: str) -> str:\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        \"max_tokens\": MAX_TOKENS,\n",
    "        \"temperature\": TEMPERATURE,\n",
    "        \"top_p\": TOP_P,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    resp = session.post(ENDPOINT, json=payload, timeout=(10, 120))\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    try:\n",
    "        return (data[\"choices\"][0][\"message\"][\"content\"] or \"\").strip()\n",
    "    except Exception:\n",
    "        raise RuntimeError(f\"Unexpected response format: {data}\")\n",
    "\n",
    "def with_retries(fn, *args):\n",
    "    last_err = None\n",
    "    for attempt in range(1, MAX_RETRIES + 1):\n",
    "        try:\n",
    "            return fn(*args), None\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            time.sleep(1.5 * attempt)\n",
    "    return None, str(last_err)\n",
    "\n",
    "# =========================\n",
    "# MAIN\n",
    "# =========================\n",
    "t0 = time.time()\n",
    "print(\"Loading INPUT json...\", flush=True)\n",
    "data = load_json(INPUT_PATH)\n",
    "print(f\"Loaded INPUT in {time.time()-t0:.1f}s | records={len(data)}\", flush=True)\n",
    "\n",
    "existing = data\n",
    "\n",
    "print(\"Pre-scan counting eligible records...\", flush=True)\n",
    "t2 = time.time()\n",
    "total_to_process = 0\n",
    "seen = 0\n",
    "for rec in existing:\n",
    "    seen += 1\n",
    "    if seen % 10000 == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Pre-scan: seen={seen} | eligible_so_far={total_to_process} | elapsed={format_hms(time.time()-t2)}\")\n",
    "    if should_process(rec):\n",
    "        total_to_process += 1\n",
    "\n",
    "clear_output(wait=True)\n",
    "print(f\"Pre-scan done: total_to_process={total_to_process} in {format_hms(time.time()-t2)}\", flush=True)\n",
    "\n",
    "processed = 0\n",
    "failed = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for rec in existing:\n",
    "    if not should_process(rec):\n",
    "        continue\n",
    "\n",
    "    mcq = rec[QA_KEY][MCQ_KEY]\n",
    "    question = (mcq.get(\"question\") or \"\").strip()\n",
    "    choices = mcq.get(\"choices\") or {}\n",
    "    answer = mcq.get(\"answer\")\n",
    "\n",
    "    call_t0 = time.time()\n",
    "    raw, err = with_retries(\n",
    "        call_llama,\n",
    "        SYSTEM_EVOL,\n",
    "        build_user_prompt_evol(question, choices, answer),\n",
    "    )\n",
    "    call_dt = time.time() - call_t0\n",
    "\n",
    "    if raw is None:\n",
    "        rec[QA_KEY][EVOL_KEY] = {}\n",
    "        rec[\"evol_error\"] = err\n",
    "        failed += 1\n",
    "    else:\n",
    "        obj = safe_parse_json_obj(raw)\n",
    "        if obj is None or not valid_evol_schema(obj):\n",
    "            rec[QA_KEY][EVOL_KEY] = {}\n",
    "            rec[\"evol_error\"] = f\"Invalid JSON/schema. Raw: {raw[:600]}\"\n",
    "            failed += 1\n",
    "        else:\n",
    "            rec[QA_KEY][EVOL_KEY] = obj\n",
    "            rec.pop(\"evol_error\", None)\n",
    "\n",
    "    processed += 1\n",
    "\n",
    "    if processed % PRINT_EVERY == 0 or processed == total_to_process:\n",
    "        elapsed = time.time() - start_time\n",
    "        rate = processed / elapsed if elapsed > 0 else 0.0\n",
    "        remaining = total_to_process - processed\n",
    "        eta = remaining / rate if rate > 0 else float(\"inf\")\n",
    "        pct = (processed / total_to_process * 100) if total_to_process > 0 else 100.0\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(\n",
    "            f\"[{processed}/{total_to_process}] {pct:6.2f}% | \"\n",
    "            f\"last_call={call_dt:.1f}s | \"\n",
    "            f\"elapsed {format_hms(elapsed)} | \"\n",
    "            f\"rate {rate:.3f} rec/s | \"\n",
    "            f\"ETA {format_hms(eta)} | failed {failed}\"\n",
    "        )\n",
    "\n",
    "    if processed % SAVE_EVERY == 0:\n",
    "        save_json(OUTPUT_PATH, existing)\n",
    "\n",
    "    time.sleep(SLEEP_BETWEEN_CALLS)\n",
    "\n",
    "save_json(OUTPUT_PATH, existing)\n",
    "\n",
    "elapsed_total = time.time() - start_time\n",
    "clear_output(wait=True)\n",
    "print(f\"Done. Processed: {processed}/{total_to_process} | failed: {failed} | total time: {format_hms(elapsed_total)}\")\n",
    "print(f\"Saved to: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76008e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[progress] idx=12 newly_scored=10 skipped_no_text=0 skipped_no_evol=3 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=10\n",
      "[progress] idx=23 newly_scored=20 skipped_no_text=0 skipped_no_evol=4 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=20\n",
      "[progress] idx=34 newly_scored=30 skipped_no_text=0 skipped_no_evol=5 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=30\n",
      "[progress] idx=44 newly_scored=40 skipped_no_text=0 skipped_no_evol=5 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=40\n",
      "[progress] idx=54 newly_scored=50 skipped_no_text=0 skipped_no_evol=5 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=50\n",
      "[progress] idx=64 newly_scored=60 skipped_no_text=0 skipped_no_evol=5 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=60\n",
      "[progress] idx=74 newly_scored=70 skipped_no_text=0 skipped_no_evol=5 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=70\n",
      "[progress] idx=86 newly_scored=80 skipped_no_text=0 skipped_no_evol=7 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=80\n",
      "[progress] idx=99 newly_scored=90 skipped_no_text=0 skipped_no_evol=10 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=90\n",
      "[progress] idx=109 newly_scored=100 skipped_no_text=0 skipped_no_evol=10 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=100\n",
      "[progress] idx=119 newly_scored=110 skipped_no_text=0 skipped_no_evol=10 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=110\n",
      "[progress] idx=131 newly_scored=120 skipped_no_text=0 skipped_no_evol=12 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=120\n",
      "[progress] idx=143 newly_scored=130 skipped_no_text=0 skipped_no_evol=14 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=130\n",
      "[progress] idx=154 newly_scored=140 skipped_no_text=0 skipped_no_evol=15 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=140\n",
      "[progress] idx=165 newly_scored=150 skipped_no_text=0 skipped_no_evol=16 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=150\n",
      "[progress] idx=177 newly_scored=160 skipped_no_text=0 skipped_no_evol=18 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=160\n",
      "[progress] idx=187 newly_scored=170 skipped_no_text=0 skipped_no_evol=18 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=170\n",
      "[progress] idx=198 newly_scored=180 skipped_no_text=0 skipped_no_evol=19 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=180\n",
      "[progress] idx=208 newly_scored=190 skipped_no_text=0 skipped_no_evol=19 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=190\n",
      "[progress] idx=218 newly_scored=200 skipped_no_text=0 skipped_no_evol=19 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=200\n",
      "[progress] idx=229 newly_scored=210 skipped_no_text=0 skipped_no_evol=20 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=210\n",
      "[progress] idx=239 newly_scored=220 skipped_no_text=0 skipped_no_evol=20 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=220\n",
      "[progress] idx=249 newly_scored=230 skipped_no_text=0 skipped_no_evol=20 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=230\n",
      "[progress] idx=259 newly_scored=240 skipped_no_text=0 skipped_no_evol=20 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=240\n",
      "[progress] idx=269 newly_scored=250 skipped_no_text=0 skipped_no_evol=20 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=250\n",
      "[progress] idx=280 newly_scored=260 skipped_no_text=0 skipped_no_evol=21 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=260\n",
      "[progress] idx=290 newly_scored=270 skipped_no_text=0 skipped_no_evol=21 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=270\n",
      "[progress] idx=301 newly_scored=280 skipped_no_text=0 skipped_no_evol=22 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=280\n",
      "[progress] idx=312 newly_scored=290 skipped_no_text=0 skipped_no_evol=23 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=290\n",
      "[progress] idx=324 newly_scored=300 skipped_no_text=0 skipped_no_evol=25 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=300\n",
      "[progress] idx=334 newly_scored=310 skipped_no_text=0 skipped_no_evol=25 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=310\n",
      "[progress] idx=344 newly_scored=320 skipped_no_text=0 skipped_no_evol=25 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=320\n",
      "[progress] idx=355 newly_scored=330 skipped_no_text=0 skipped_no_evol=26 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=330\n",
      "[progress] idx=365 newly_scored=340 skipped_no_text=0 skipped_no_evol=26 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=340\n",
      "[progress] idx=375 newly_scored=350 skipped_no_text=0 skipped_no_evol=26 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=350\n",
      "[progress] idx=387 newly_scored=360 skipped_no_text=0 skipped_no_evol=28 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=360\n",
      "[progress] idx=398 newly_scored=370 skipped_no_text=0 skipped_no_evol=29 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=370\n",
      "[progress] idx=409 newly_scored=380 skipped_no_text=0 skipped_no_evol=30 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=380\n",
      "[progress] idx=419 newly_scored=390 skipped_no_text=0 skipped_no_evol=30 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=390\n",
      "[progress] idx=429 newly_scored=400 skipped_no_text=0 skipped_no_evol=30 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=400\n",
      "[progress] idx=441 newly_scored=410 skipped_no_text=0 skipped_no_evol=32 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=410\n",
      "[progress] idx=452 newly_scored=420 skipped_no_text=0 skipped_no_evol=33 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=420\n",
      "[progress] idx=462 newly_scored=430 skipped_no_text=0 skipped_no_evol=33 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=430\n",
      "[progress] idx=474 newly_scored=440 skipped_no_text=0 skipped_no_evol=35 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=440\n",
      "[progress] idx=486 newly_scored=450 skipped_no_text=0 skipped_no_evol=37 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=450\n",
      "[progress] idx=497 newly_scored=460 skipped_no_text=0 skipped_no_evol=38 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=460\n",
      "[progress] idx=508 newly_scored=470 skipped_no_text=0 skipped_no_evol=39 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=470\n",
      "[progress] idx=520 newly_scored=480 skipped_no_text=0 skipped_no_evol=41 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=480\n",
      "[progress] idx=531 newly_scored=490 skipped_no_text=0 skipped_no_evol=42 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=490\n",
      "[progress] idx=542 newly_scored=500 skipped_no_text=0 skipped_no_evol=43 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=500\n",
      "[progress] idx=553 newly_scored=510 skipped_no_text=0 skipped_no_evol=44 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=510\n",
      "[progress] idx=565 newly_scored=520 skipped_no_text=0 skipped_no_evol=46 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=520\n",
      "[progress] idx=576 newly_scored=530 skipped_no_text=0 skipped_no_evol=47 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=530\n",
      "[progress] idx=588 newly_scored=540 skipped_no_text=0 skipped_no_evol=49 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=540\n",
      "[progress] idx=599 newly_scored=550 skipped_no_text=0 skipped_no_evol=50 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=550\n",
      "[progress] idx=609 newly_scored=560 skipped_no_text=0 skipped_no_evol=50 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=560\n",
      "[progress] idx=619 newly_scored=570 skipped_no_text=0 skipped_no_evol=50 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=570\n",
      "[progress] idx=630 newly_scored=580 skipped_no_text=0 skipped_no_evol=51 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=580\n",
      "[progress] idx=640 newly_scored=590 skipped_no_text=0 skipped_no_evol=51 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=590\n",
      "[progress] idx=651 newly_scored=600 skipped_no_text=0 skipped_no_evol=52 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=600\n",
      "[progress] idx=663 newly_scored=610 skipped_no_text=0 skipped_no_evol=54 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=610\n",
      "[progress] idx=674 newly_scored=620 skipped_no_text=0 skipped_no_evol=55 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=620\n",
      "[progress] idx=684 newly_scored=630 skipped_no_text=0 skipped_no_evol=55 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=630\n",
      "[progress] idx=696 newly_scored=640 skipped_no_text=0 skipped_no_evol=57 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=640\n",
      "[progress] idx=710 newly_scored=650 skipped_no_text=0 skipped_no_evol=61 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=650\n",
      "[progress] idx=722 newly_scored=660 skipped_no_text=0 skipped_no_evol=63 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=660\n",
      "[progress] idx=732 newly_scored=670 skipped_no_text=0 skipped_no_evol=63 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=670\n",
      "[progress] idx=742 newly_scored=680 skipped_no_text=0 skipped_no_evol=63 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=680\n",
      "[progress] idx=752 newly_scored=690 skipped_no_text=0 skipped_no_evol=63 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=690\n",
      "[progress] idx=764 newly_scored=700 skipped_no_text=0 skipped_no_evol=65 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=700\n",
      "[progress] idx=774 newly_scored=710 skipped_no_text=0 skipped_no_evol=65 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=710\n",
      "[progress] idx=786 newly_scored=720 skipped_no_text=0 skipped_no_evol=67 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=720\n",
      "[progress] idx=801 newly_scored=730 skipped_no_text=0 skipped_no_evol=72 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=730\n",
      "[progress] idx=812 newly_scored=740 skipped_no_text=0 skipped_no_evol=73 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=740\n",
      "[progress] idx=822 newly_scored=750 skipped_no_text=0 skipped_no_evol=73 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=750\n",
      "[progress] idx=832 newly_scored=760 skipped_no_text=0 skipped_no_evol=73 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=760\n",
      "[progress] idx=843 newly_scored=770 skipped_no_text=0 skipped_no_evol=74 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=770\n",
      "[progress] idx=856 newly_scored=780 skipped_no_text=0 skipped_no_evol=77 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=780\n",
      "[progress] idx=866 newly_scored=790 skipped_no_text=0 skipped_no_evol=77 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=790\n",
      "[progress] idx=877 newly_scored=800 skipped_no_text=0 skipped_no_evol=78 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=800\n",
      "[progress] idx=889 newly_scored=810 skipped_no_text=0 skipped_no_evol=80 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=810\n",
      "[progress] idx=901 newly_scored=820 skipped_no_text=0 skipped_no_evol=82 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=820\n",
      "[progress] idx=911 newly_scored=830 skipped_no_text=0 skipped_no_evol=82 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=830\n",
      "[progress] idx=923 newly_scored=840 skipped_no_text=0 skipped_no_evol=84 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=840\n",
      "[progress] idx=933 newly_scored=850 skipped_no_text=0 skipped_no_evol=84 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=850\n",
      "[progress] idx=943 newly_scored=860 skipped_no_text=0 skipped_no_evol=84 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=860\n",
      "[progress] idx=955 newly_scored=870 skipped_no_text=0 skipped_no_evol=86 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=870\n",
      "[progress] idx=966 newly_scored=880 skipped_no_text=0 skipped_no_evol=87 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=880\n",
      "[progress] idx=977 newly_scored=890 skipped_no_text=0 skipped_no_evol=88 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=890\n",
      "[progress] idx=987 newly_scored=900 skipped_no_text=0 skipped_no_evol=88 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=900\n",
      "[progress] idx=997 newly_scored=910 skipped_no_text=0 skipped_no_evol=88 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json at newly_scored=910\n",
      "[done] newly_scored=911 skipped_no_text=0 skipped_no_evol=89 parse_fail=0\n",
      "[done] output saved to /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json\n"
     ]
    }
   ],
   "source": [
    "#genericness - Score :\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from typing import Any, Dict, Optional, List\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "INPUT_PATH  = \"../Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol.json\"\n",
    "OUTPUT_PATH = \"../Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json\"\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "ENDPOINT   = \"..\"\n",
    "\n",
    "SAVE_EVERY = 10\n",
    "SLEEP_BETWEEN_CALLS = 0.10\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "MAX_TOKENS = 32          \n",
    "TEMPERATURE = 0.2\n",
    "TOP_P = 0.95\n",
    "\n",
    "PRINT_EVERY = 10\n",
    "\n",
    "QA_KEY   = \"qa_fa\"\n",
    "EVOL_KEY = \"mcq_evol\"\n",
    "\n",
    "\n",
    "SOURCE_TEXT_KEYS_QA = [\"text\"]\n",
    "\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a strict evaluator. \"\n",
    "    \"Return ONLY a single integer: 1, 2, 3, 4, or 5. \"\n",
    "    \"No other text, no punctuation, no JSON.\"\n",
    ")\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"\\\n",
    "Rubric (Genericness score 1-5):\n",
    "1: Fully generic - General/abstract; can be answered correctly without referring to the SOURCE TEXT.\n",
    "2: Mostly generic - Lightly anchored to the SOURCE TEXT, but still answerable using general knowledge alone.\n",
    "3: Partial - Some specific references to the SOURCE TEXT, yet remains somewhat general.\n",
    "4: Mostly specific - Clearly grounded in the SOURCE TEXT with one strong, identifiable textual cue.\n",
    "5: Highly specific - Two or more clear, specific cues from the SOURCE TEXT that are necessary to answer.\n",
    "\n",
    "Task:\n",
    "Given SOURCE TEXT and the evolved MCQ, output ONLY the genericness score as a single integer in [1..5].\n",
    "Do NOT explain. Do NOT output anything except the digit.\n",
    "\n",
    "SOURCE TEXT:\n",
    "{source_text}\n",
    "\n",
    "EVOLVED MCQ:\n",
    "Question: {question}\n",
    "Options:\n",
    "A) {opt_a}\n",
    "B) {opt_b}\n",
    "C) {opt_c}\n",
    "D) {opt_d}\n",
    "CorrectAnswer: {correct}\n",
    "\"\"\"\n",
    "\n",
    "SCORE_RE = re.compile(r\"\\b([1-5])\\b\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# File I/O\n",
    "# -------------------------\n",
    "def load_json(path: str) -> Any:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(path: str, data: Any) -> None:\n",
    "    tmp = path + \".tmp\"\n",
    "    with open(tmp, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    os.replace(tmp, path)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "def _first_nonempty_str(d: Dict[str, Any], keys: List[str]) -> Optional[str]:\n",
    "    for k in keys:\n",
    "        v = d.get(k)\n",
    "        if isinstance(v, str) and v.strip():\n",
    "            return v.strip()\n",
    "    return None\n",
    "\n",
    "def get_source_text(item: Dict[str, Any]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Priority:\n",
    "    1) qa_fa-level keys (most common)\n",
    "    2) item-level keys\n",
    "    \"\"\"\n",
    "    qa = item.get(QA_KEY)\n",
    "    if isinstance(qa, dict):\n",
    "        t = _first_nonempty_str(qa, SOURCE_TEXT_KEYS_QA)\n",
    "        if t:\n",
    "            return t\n",
    "    return _first_nonempty_str(item, SOURCE_TEXT_KEYS_ITEM)\n",
    "\n",
    "def build_prompt(source_text: str, evol: Dict[str, Any]) -> str:\n",
    "    q = evol.get(\"rewritten_question\", \"\") or \"\"\n",
    "    opts = evol.get(\"rewritten_options\", {}) or {}\n",
    "\n",
    "    a = opts.get(\"A\", \"\") or \"\"\n",
    "    b = opts.get(\"B\", \"\") or \"\"\n",
    "    c = opts.get(\"C\", \"\") or \"\"\n",
    "    d = opts.get(\"D\", \"\") or \"\"\n",
    "\n",
    "    correct = evol.get(\"correct_answer\", \"\") or \"\"\n",
    "\n",
    "    return USER_PROMPT_TEMPLATE.format(\n",
    "        source_text=source_text,\n",
    "        question=q,\n",
    "        opt_a=a,\n",
    "        opt_b=b,\n",
    "        opt_c=c,\n",
    "        opt_d=d,\n",
    "        correct=correct,\n",
    "    )\n",
    "\n",
    "def parse_score_only(raw_text: str) -> int:\n",
    "    txt = (raw_text or \"\").strip()\n",
    "    m = SCORE_RE.search(txt)\n",
    "    if not m:\n",
    "        raise ValueError(f\"No valid score 1..5 found. Output: {txt[:200]}\")\n",
    "    return int(m.group(1))\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# LLM call\n",
    "# -------------------------\n",
    "def call_llama(prompt: str) -> str:\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        \"max_tokens\": MAX_TOKENS,\n",
    "        \"temperature\": TEMPERATURE,\n",
    "        \"top_p\": TOP_P,\n",
    "    }\n",
    "\n",
    "    last_err = None\n",
    "    for attempt in range(1, MAX_RETRIES + 1):\n",
    "        try:\n",
    "            r = requests.post(ENDPOINT, json=payload, timeout=120)\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            return data[\"choices\"][0][\"message\"][\"content\"]\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            if attempt < MAX_RETRIES:\n",
    "                time.sleep(0.8 * attempt)\n",
    "            else:\n",
    "                raise RuntimeError(f\"LLM call failed after {MAX_RETRIES} retries: {last_err}\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Main\n",
    "# -------------------------\n",
    "def main():\n",
    "    data = load_json(INPUT_PATH)\n",
    "    if not isinstance(data, list):\n",
    "        raise ValueError(\"Expected top-level JSON to be a list of items.\")\n",
    "\n",
    "    newly_scored = 0\n",
    "    skipped_no_evol = 0\n",
    "    skipped_no_text = 0\n",
    "    parse_fail = 0\n",
    "\n",
    "    for idx, item in enumerate(data):\n",
    "        qa = item.get(QA_KEY)\n",
    "        if not isinstance(qa, dict):\n",
    "            continue\n",
    "\n",
    "        evol = qa.get(EVOL_KEY)\n",
    "        if not isinstance(evol, dict):\n",
    "            skipped_no_evol += 1\n",
    "            continue\n",
    "\n",
    "        # skip already-scored\n",
    "        existing = evol.get(\"genericness_score\")\n",
    "        if isinstance(existing, int) and existing in [1, 2, 3, 4, 5]:\n",
    "            continue\n",
    "\n",
    "        source_text = get_source_text(item)\n",
    "        if not source_text:\n",
    "            skipped_no_text += 1\n",
    "            continue\n",
    "\n",
    "        prompt = build_prompt(source_text, evol)\n",
    "\n",
    "        raw = call_llama(prompt)\n",
    "        try:\n",
    "            score = parse_score_only(raw)\n",
    "            evol[\"genericness_score\"] = score\n",
    "        except Exception:\n",
    "            evol[\"genericness_score\"] = None\n",
    "            parse_fail += 1\n",
    "\n",
    "        newly_scored += 1\n",
    "\n",
    "        if newly_scored % PRINT_EVERY == 0:\n",
    "            print(f\"[progress] idx={idx} newly_scored={newly_scored} \"\n",
    "                  f\"skipped_no_text={skipped_no_text} skipped_no_evol={skipped_no_evol} \"\n",
    "                  f\"parse_fail={parse_fail}\")\n",
    "\n",
    "        if newly_scored % SAVE_EVERY == 0:\n",
    "            save_json(OUTPUT_PATH, data)\n",
    "            print(f\"[checkpoint] saved {OUTPUT_PATH} at newly_scored={newly_scored}\")\n",
    "\n",
    "        time.sleep(SLEEP_BETWEEN_CALLS)\n",
    "\n",
    "    save_json(OUTPUT_PATH, data)\n",
    "    print(f\"[done] newly_scored={newly_scored} skipped_no_text={skipped_no_text} \"\n",
    "          f\"skipped_no_evol={skipped_no_evol} parse_fail={parse_fail}\")\n",
    "    print(f\"[done] output saved to {OUTPUT_PATH}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca0e602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[progress] idx=12 newly_scored=10 skipped_no_text=0 skipped_no_evol=3 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=10\n",
      "[progress] idx=23 newly_scored=20 skipped_no_text=0 skipped_no_evol=4 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=20\n",
      "[progress] idx=34 newly_scored=30 skipped_no_text=0 skipped_no_evol=5 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=30\n",
      "[progress] idx=44 newly_scored=40 skipped_no_text=0 skipped_no_evol=5 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=40\n",
      "[progress] idx=54 newly_scored=50 skipped_no_text=0 skipped_no_evol=5 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=50\n",
      "[progress] idx=64 newly_scored=60 skipped_no_text=0 skipped_no_evol=5 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=60\n",
      "[progress] idx=74 newly_scored=70 skipped_no_text=0 skipped_no_evol=5 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=70\n",
      "[progress] idx=86 newly_scored=80 skipped_no_text=0 skipped_no_evol=7 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=80\n",
      "[progress] idx=99 newly_scored=90 skipped_no_text=0 skipped_no_evol=10 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=90\n",
      "[progress] idx=109 newly_scored=100 skipped_no_text=0 skipped_no_evol=10 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=100\n",
      "[progress] idx=119 newly_scored=110 skipped_no_text=0 skipped_no_evol=10 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=110\n",
      "[progress] idx=131 newly_scored=120 skipped_no_text=0 skipped_no_evol=12 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=120\n",
      "[progress] idx=143 newly_scored=130 skipped_no_text=0 skipped_no_evol=14 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=130\n",
      "[progress] idx=154 newly_scored=140 skipped_no_text=0 skipped_no_evol=15 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=140\n",
      "[progress] idx=165 newly_scored=150 skipped_no_text=0 skipped_no_evol=16 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=150\n",
      "[progress] idx=177 newly_scored=160 skipped_no_text=0 skipped_no_evol=18 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=160\n",
      "[progress] idx=187 newly_scored=170 skipped_no_text=0 skipped_no_evol=18 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=170\n",
      "[progress] idx=198 newly_scored=180 skipped_no_text=0 skipped_no_evol=19 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=180\n",
      "[progress] idx=208 newly_scored=190 skipped_no_text=0 skipped_no_evol=19 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=190\n",
      "[progress] idx=218 newly_scored=200 skipped_no_text=0 skipped_no_evol=19 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=200\n",
      "[progress] idx=229 newly_scored=210 skipped_no_text=0 skipped_no_evol=20 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=210\n",
      "[progress] idx=239 newly_scored=220 skipped_no_text=0 skipped_no_evol=20 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=220\n",
      "[progress] idx=249 newly_scored=230 skipped_no_text=0 skipped_no_evol=20 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=230\n",
      "[progress] idx=259 newly_scored=240 skipped_no_text=0 skipped_no_evol=20 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=240\n",
      "[progress] idx=269 newly_scored=250 skipped_no_text=0 skipped_no_evol=20 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=250\n",
      "[progress] idx=280 newly_scored=260 skipped_no_text=0 skipped_no_evol=21 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=260\n",
      "[progress] idx=290 newly_scored=270 skipped_no_text=0 skipped_no_evol=21 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=270\n",
      "[progress] idx=301 newly_scored=280 skipped_no_text=0 skipped_no_evol=22 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=280\n",
      "[progress] idx=312 newly_scored=290 skipped_no_text=0 skipped_no_evol=23 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=290\n",
      "[progress] idx=324 newly_scored=300 skipped_no_text=0 skipped_no_evol=25 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=300\n",
      "[progress] idx=334 newly_scored=310 skipped_no_text=0 skipped_no_evol=25 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=310\n",
      "[progress] idx=344 newly_scored=320 skipped_no_text=0 skipped_no_evol=25 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=320\n",
      "[progress] idx=355 newly_scored=330 skipped_no_text=0 skipped_no_evol=26 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=330\n",
      "[progress] idx=365 newly_scored=340 skipped_no_text=0 skipped_no_evol=26 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=340\n",
      "[progress] idx=375 newly_scored=350 skipped_no_text=0 skipped_no_evol=26 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=350\n",
      "[progress] idx=387 newly_scored=360 skipped_no_text=0 skipped_no_evol=28 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=360\n",
      "[progress] idx=398 newly_scored=370 skipped_no_text=0 skipped_no_evol=29 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=370\n",
      "[progress] idx=409 newly_scored=380 skipped_no_text=0 skipped_no_evol=30 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=380\n",
      "[progress] idx=419 newly_scored=390 skipped_no_text=0 skipped_no_evol=30 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=390\n",
      "[progress] idx=429 newly_scored=400 skipped_no_text=0 skipped_no_evol=30 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=400\n",
      "[progress] idx=441 newly_scored=410 skipped_no_text=0 skipped_no_evol=32 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=410\n",
      "[progress] idx=452 newly_scored=420 skipped_no_text=0 skipped_no_evol=33 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=420\n",
      "[progress] idx=462 newly_scored=430 skipped_no_text=0 skipped_no_evol=33 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=430\n",
      "[progress] idx=474 newly_scored=440 skipped_no_text=0 skipped_no_evol=35 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=440\n",
      "[progress] idx=486 newly_scored=450 skipped_no_text=0 skipped_no_evol=37 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=450\n",
      "[progress] idx=497 newly_scored=460 skipped_no_text=0 skipped_no_evol=38 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=460\n",
      "[progress] idx=508 newly_scored=470 skipped_no_text=0 skipped_no_evol=39 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=470\n",
      "[progress] idx=520 newly_scored=480 skipped_no_text=0 skipped_no_evol=41 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=480\n",
      "[progress] idx=531 newly_scored=490 skipped_no_text=0 skipped_no_evol=42 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=490\n",
      "[progress] idx=542 newly_scored=500 skipped_no_text=0 skipped_no_evol=43 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=500\n",
      "[progress] idx=553 newly_scored=510 skipped_no_text=0 skipped_no_evol=44 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=510\n",
      "[progress] idx=565 newly_scored=520 skipped_no_text=0 skipped_no_evol=46 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=520\n",
      "[progress] idx=576 newly_scored=530 skipped_no_text=0 skipped_no_evol=47 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=530\n",
      "[progress] idx=588 newly_scored=540 skipped_no_text=0 skipped_no_evol=49 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=540\n",
      "[progress] idx=599 newly_scored=550 skipped_no_text=0 skipped_no_evol=50 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=550\n",
      "[progress] idx=609 newly_scored=560 skipped_no_text=0 skipped_no_evol=50 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=560\n",
      "[progress] idx=619 newly_scored=570 skipped_no_text=0 skipped_no_evol=50 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=570\n",
      "[progress] idx=630 newly_scored=580 skipped_no_text=0 skipped_no_evol=51 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=580\n",
      "[progress] idx=640 newly_scored=590 skipped_no_text=0 skipped_no_evol=51 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=590\n",
      "[progress] idx=651 newly_scored=600 skipped_no_text=0 skipped_no_evol=52 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=600\n",
      "[progress] idx=663 newly_scored=610 skipped_no_text=0 skipped_no_evol=54 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=610\n",
      "[progress] idx=674 newly_scored=620 skipped_no_text=0 skipped_no_evol=55 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=620\n",
      "[progress] idx=684 newly_scored=630 skipped_no_text=0 skipped_no_evol=55 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=630\n",
      "[progress] idx=696 newly_scored=640 skipped_no_text=0 skipped_no_evol=57 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=640\n",
      "[progress] idx=710 newly_scored=650 skipped_no_text=0 skipped_no_evol=61 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=650\n",
      "[progress] idx=722 newly_scored=660 skipped_no_text=0 skipped_no_evol=63 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=660\n",
      "[progress] idx=732 newly_scored=670 skipped_no_text=0 skipped_no_evol=63 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=670\n",
      "[progress] idx=742 newly_scored=680 skipped_no_text=0 skipped_no_evol=63 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=680\n",
      "[progress] idx=752 newly_scored=690 skipped_no_text=0 skipped_no_evol=63 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=690\n",
      "[progress] idx=764 newly_scored=700 skipped_no_text=0 skipped_no_evol=65 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=700\n",
      "[progress] idx=774 newly_scored=710 skipped_no_text=0 skipped_no_evol=65 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=710\n",
      "[progress] idx=786 newly_scored=720 skipped_no_text=0 skipped_no_evol=67 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=720\n",
      "[progress] idx=801 newly_scored=730 skipped_no_text=0 skipped_no_evol=72 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=730\n",
      "[progress] idx=812 newly_scored=740 skipped_no_text=0 skipped_no_evol=73 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=740\n",
      "[progress] idx=822 newly_scored=750 skipped_no_text=0 skipped_no_evol=73 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=750\n",
      "[progress] idx=832 newly_scored=760 skipped_no_text=0 skipped_no_evol=73 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=760\n",
      "[progress] idx=843 newly_scored=770 skipped_no_text=0 skipped_no_evol=74 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=770\n",
      "[progress] idx=856 newly_scored=780 skipped_no_text=0 skipped_no_evol=77 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=780\n",
      "[progress] idx=866 newly_scored=790 skipped_no_text=0 skipped_no_evol=77 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=790\n",
      "[progress] idx=877 newly_scored=800 skipped_no_text=0 skipped_no_evol=78 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=800\n",
      "[progress] idx=889 newly_scored=810 skipped_no_text=0 skipped_no_evol=80 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=810\n",
      "[progress] idx=901 newly_scored=820 skipped_no_text=0 skipped_no_evol=82 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=820\n",
      "[progress] idx=911 newly_scored=830 skipped_no_text=0 skipped_no_evol=82 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=830\n",
      "[progress] idx=923 newly_scored=840 skipped_no_text=0 skipped_no_evol=84 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=840\n",
      "[progress] idx=933 newly_scored=850 skipped_no_text=0 skipped_no_evol=84 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=850\n",
      "[progress] idx=943 newly_scored=860 skipped_no_text=0 skipped_no_evol=84 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=860\n",
      "[progress] idx=955 newly_scored=870 skipped_no_text=0 skipped_no_evol=86 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=870\n",
      "[progress] idx=966 newly_scored=880 skipped_no_text=0 skipped_no_evol=87 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=880\n",
      "[progress] idx=977 newly_scored=890 skipped_no_text=0 skipped_no_evol=88 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=890\n",
      "[progress] idx=987 newly_scored=900 skipped_no_text=0 skipped_no_evol=88 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=900\n",
      "[progress] idx=997 newly_scored=910 skipped_no_text=0 skipped_no_evol=88 parse_fail=0\n",
      "[checkpoint] saved /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json at newly_scored=910\n",
      "[done] newly_scored=911 skipped_no_text=0 skipped_no_evol=89 parse_fail=0\n",
      "[done] output saved to /home/llm-mehrnoush/Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from typing import Any, Dict, Optional, List\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "INPUT_PATH  = \"../Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN.json\"\n",
    "OUTPUT_PATH = \"../Dataset-commonSence/traditions_and_customs_1_with_mcq_fa_T_evol_GN_RD.json\"\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "ENDPOINT   = \"..\"\n",
    "\n",
    "SAVE_EVERY = 10\n",
    "SLEEP_BETWEEN_CALLS = 0.10\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "MAX_TOKENS = 32\n",
    "TEMPERATURE = 0.2\n",
    "TOP_P = 0.95\n",
    "\n",
    "PRINT_EVERY = 10\n",
    "\n",
    "QA_KEY   = \"qa_fa\"\n",
    "EVOL_KEY = \"mcq_evol\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Reasoning Depth prompt (STRICT: digit only)\n",
    "# -------------------------\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a strict evaluator. \"\n",
    "    \"Return ONLY a single integer: 1, 2, 3, 4, or 5. \"\n",
    "    \"No other text, no punctuation, no JSON.\"\n",
    ")\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"\\\n",
    "Definition (Reasoning Depth):\n",
    "Does arriving at the correct answer require more than one step of reasoning?\n",
    "\n",
    "Scores:\n",
    "1: Direct/obvious answer; almost no reasoning\n",
    "2: One simple step (e.g., a simple cause–effect relation)\n",
    "3: Two identifiable steps (combining two pieces of information)\n",
    "4: Multiple points plus the need for synthesis/comparison/inference\n",
    "5: Clear multi-step reasoning with constraints or cases; unambiguous\n",
    "\n",
    "Task:\n",
    "Given SOURCE TEXT and the evolved MCQ, output ONLY the Reasoning Depth score as a single integer in [1..5].\n",
    "Do NOT explain. Output nothing except the digit.\n",
    "\n",
    "SOURCE TEXT:\n",
    "{source_text}\n",
    "\n",
    "EVOLVED MCQ:\n",
    "Question: {question}\n",
    "Options:\n",
    "A) {opt_a}\n",
    "B) {opt_b}\n",
    "C) {opt_c}\n",
    "D) {opt_d}\n",
    "CorrectAnswer: {correct}\n",
    "\"\"\"\n",
    "\n",
    "SCORE_RE = re.compile(r\"\\b([1-5])\\b\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# File I/O\n",
    "# -------------------------\n",
    "def load_json(path: str) -> Any:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(path: str, data: Any) -> None:\n",
    "    tmp = path + \".tmp\"\n",
    "    with open(tmp, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    os.replace(tmp, path)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "def _first_nonempty_str(d: Dict[str, Any], keys: List[str]) -> Optional[str]:\n",
    "    for k in keys:\n",
    "        v = d.get(k)\n",
    "        if isinstance(v, str) and v.strip():\n",
    "            return v.strip()\n",
    "    return None\n",
    "\n",
    "def get_source_text(item: Dict[str, Any]) -> Optional[str]:\n",
    "    qa = item.get(QA_KEY)\n",
    "    if isinstance(qa, dict):\n",
    "        t = _first_nonempty_str(qa, SOURCE_TEXT_KEYS_QA)\n",
    "        if t:\n",
    "            return t\n",
    "    return _first_nonempty_str(item, SOURCE_TEXT_KEYS_ITEM)\n",
    "\n",
    "def build_prompt(source_text: str, evol: Dict[str, Any]) -> str:\n",
    "    q = evol.get(\"rewritten_question\", \"\") or \"\"\n",
    "    opts = evol.get(\"rewritten_options\", {}) or {}\n",
    "    a = opts.get(\"A\", \"\") or \"\"\n",
    "    b = opts.get(\"B\", \"\") or \"\"\n",
    "    c = opts.get(\"C\", \"\") or \"\"\n",
    "    d = opts.get(\"D\", \"\") or \"\"\n",
    "    correct = evol.get(\"correct_answer\", \"\") or \"\"\n",
    "    return USER_PROMPT_TEMPLATE.format(\n",
    "        source_text=source_text,\n",
    "        question=q,\n",
    "        opt_a=a, opt_b=b, opt_c=c, opt_d=d,\n",
    "        correct=correct,\n",
    "    )\n",
    "\n",
    "def parse_score_only(raw_text: str) -> int:\n",
    "    txt = (raw_text or \"\").strip()\n",
    "    m = SCORE_RE.search(txt)\n",
    "    if not m:\n",
    "        raise ValueError(f\"No valid score 1..5 found. Output: {txt[:200]}\")\n",
    "    return int(m.group(1))\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# LLM call\n",
    "# -------------------------\n",
    "def call_llama(prompt: str) -> str:\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        \"max_tokens\": MAX_TOKENS,\n",
    "        \"temperature\": TEMPERATURE,\n",
    "        \"top_p\": TOP_P,\n",
    "    }\n",
    "\n",
    "    last_err = None\n",
    "    for attempt in range(1, MAX_RETRIES + 1):\n",
    "        try:\n",
    "            r = requests.post(ENDPOINT, json=payload, timeout=120)\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            return data[\"choices\"][0][\"message\"][\"content\"]\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            if attempt < MAX_RETRIES:\n",
    "                time.sleep(0.8 * attempt)\n",
    "            else:\n",
    "                raise RuntimeError(f\"LLM call failed after {MAX_RETRIES} retries: {last_err}\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Main\n",
    "# -------------------------\n",
    "def main():\n",
    "    data = load_json(INPUT_PATH)\n",
    "    if not isinstance(data, list):\n",
    "        raise ValueError(\"Expected top-level JSON to be a list.\")\n",
    "\n",
    "    newly_scored = 0\n",
    "    skipped_no_text = 0\n",
    "    skipped_no_evol = 0\n",
    "    parse_fail = 0\n",
    "\n",
    "    for idx, item in enumerate(data):\n",
    "        qa = item.get(QA_KEY)\n",
    "        if not isinstance(qa, dict):\n",
    "            continue\n",
    "\n",
    "        evol = qa.get(EVOL_KEY)\n",
    "        if not isinstance(evol, dict):\n",
    "            skipped_no_evol += 1\n",
    "            continue\n",
    "\n",
    "        # skip if already exists\n",
    "        existing = evol.get(\"reasoning_depth\")\n",
    "        if isinstance(existing, int) and existing in [1, 2, 3, 4, 5]:\n",
    "            continue\n",
    "\n",
    "        source_text = get_source_text(item)\n",
    "        if not source_text:\n",
    "            skipped_no_text += 1\n",
    "            continue\n",
    "\n",
    "        prompt = build_prompt(source_text, evol)\n",
    "\n",
    "        raw = call_llama(prompt)\n",
    "        try:\n",
    "            score = parse_score_only(raw)\n",
    "            evol[\"reasoning_depth\"] = score\n",
    "        except Exception:\n",
    "            evol[\"reasoning_depth\"] = None\n",
    "            parse_fail += 1\n",
    "\n",
    "        newly_scored += 1\n",
    "\n",
    "        if newly_scored % PRINT_EVERY == 0:\n",
    "            print(f\"[progress] idx={idx} newly_scored={newly_scored} \"\n",
    "                  f\"skipped_no_text={skipped_no_text} skipped_no_evol={skipped_no_evol} \"\n",
    "                  f\"parse_fail={parse_fail}\")\n",
    "\n",
    "        if newly_scored % SAVE_EVERY == 0:\n",
    "            save_json(OUTPUT_PATH, data)\n",
    "            print(f\"[checkpoint] saved {OUTPUT_PATH} at newly_scored={newly_scored}\")\n",
    "\n",
    "        time.sleep(SLEEP_BETWEEN_CALLS)\n",
    "\n",
    "    save_json(OUTPUT_PATH, data)\n",
    "    print(f\"[done] newly_scored={newly_scored} skipped_no_text={skipped_no_text} \"\n",
    "          f\"skipped_no_evol={skipped_no_evol} parse_fail={parse_fail}\")\n",
    "    print(f\"[done] output saved to {OUTPUT_PATH}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
